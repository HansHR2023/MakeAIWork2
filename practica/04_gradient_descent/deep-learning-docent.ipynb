{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "783305be-8517-4058-a458-23956ad0be80",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad7ed7f-ad3f-46cd-9b05-b424251cf191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install ipywidgets\n",
    "# !pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d5d78-a879-492f-ab43-d12b79c0af6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rnd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eb9983-c570-4454-8195-6c64977c659c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bronnen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f3a8dc-4d1a-46aa-b4e9-89c24cfb16f0",
   "metadata": {},
   "source": [
    "**Fast.ai**\n",
    "\n",
    "+ [Practical Deep Learning for Coders](https://course.fast.ai/)\n",
    "+ [Neural net foundations](https://course.fast.ai/Lessons/lesson3.html)\n",
    "\n",
    "**CodingTrain**:\n",
    "\n",
    "+ [Linear Regression with Gradient Descent](https://www.youtube.com/watch?v=L-Lsfu4ab74)\n",
    "+ [Mathematics of Gradient Descent](https://www.youtube.com/watch?v=jc2IthslyzM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689fee69-062e-4dd9-b642-1a15b22a84ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m2 = [100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770, 780, 790, 800, 810, 820, 830, 840, 850, 860, 870, 880, 890, 900, 910, 920, 930, 940, 950, 960, 970, 980, 990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8dba48-750c-4ecb-8740-856c0c40e6cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prices = [384.91367692954503, 389.8967479767937, 401.20788969026364, 465.1388607569204, 414.0688201351979, 325.18526099613297, 460.2622840847401, 425.28637650519823, 435.81289210983635, 466.1119350690599, 481.26084158347044, 553.44910806194, 524.9645554759068, 493.73550242106825, 441.31748783586255, 428.9736342758598, 524.2439536647842, 605.7756579042834, 523.9159804732369, 520.5573694360451, 572.2243354280608, 440.25182913939256, 527.1405877998808, 590.3253772815467, 624.1383069765612, 553.1559229141405, 603.3619901081537, 601.374941452989, 645.7628766092549, 520.074445002628, 644.777548130977, 505.9835725792402, 435.60382044468037, 583.5176490260349, 568.8932967557804, 701.3208570139484, 693.4986129729026, 568.6647681093013, 720.31529963436, 597.8458023030355, 668.9629307564601, 661.4270155430428, 697.0093900222645, 753.3045418080637, 747.688965355471, 734.4919571308446, 762.4963668464409, 757.4944426355083, 687.111017434628, 687.7840234328396, 712.102220810479, 786.9528480333747, 741.4919100301831, 929.5027955736383, 715.6495220469454, 703.0787780068489, 840.7931460828787, 893.5294986940426, 836.3984883587482, 866.5072142177371, 914.8441484209513, 815.4180766788587, 729.3928746802716, 798.7546416176901, 909.7027030121603, 748.9425115745198, 859.3471924551083, 881.7266151539443, 848.9085484630431, 928.6542390457668, 925.6545819068597, 1054.4985961830512, 942.3977437441195, 863.3417578949857, 873.6741685366178, 861.7893229130596, 993.6591491871075, 894.321701563041, 936.0817458409582, 1000.4511833502772, 904.3575906544015, 941.4439425467597, 840.1099614077259, 900.2264966672901, 943.2584511465706, 1019.103269196167, 1080.5445290710309, 1002.7073230785402, 1029.2954995439861, 1029.7578557983063]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192806ff-291c-4c27-83ac-22b14753bbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def manualFit(w, b):\n",
    "    fit = [w * x + b for x in m2]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set(xlim=[0, 1100], ylim=[0, 1100], xlabel='Oppervlakte in m2', ylabel='Prijs in duizend euro', title='Huisprijs')\n",
    "    \n",
    "    plt.scatter(m2, prices)\n",
    "    plt.plot(m2, fit, 'red')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "interact(manualFit, w=(-2,2,0.01), b=(-1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3c443-70cb-422c-98bf-d25de4f048f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def error(actual, predicted):\n",
    "    return actual - predicted\n",
    "\n",
    "def loss(fit):\n",
    "    l = 0\n",
    "    # Sum of squared errors\n",
    "    for i in range(0, len(m2)):\n",
    "        err = error(prices[i], fit[i])\n",
    "        l += (err**2)\n",
    "    return math.sqrt(l / len(m2))\n",
    "\n",
    "def manualFit(w, b):\n",
    "    fit = [w * x + b for x in m2]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set(xlim=[0, 1100], ylim=[0, 1100], xlabel='Oppervlakte in m2', ylabel='Prijs in duizend euro', title='Huisprijs')\n",
    "    \n",
    "    plt.scatter(m2, prices)\n",
    "    plt.plot(m2, fit, 'red')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(loss(fit))\n",
    "    \n",
    "interact(manualFit, w=(-2,2,0.01), b=(-1000,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eebb08-e24b-4f99-a22b-2ae89d0ce43f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7336d81e-3fbe-405b-8924-5fb9d995dbc1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b49e5-4e09-47c1-bc79-5819674625ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "def preparePlot(t):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set(xlim=[-10, 10], ylim=[-50, 400], xlabel='x', ylabel='y', title=t)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def plotCurve(x, y, scatter):\n",
    "\n",
    "    if scatter:\n",
    "        \n",
    "        plt.scatter(x, y)\n",
    "        \n",
    "    else:\n",
    "        plt.plot(x, y, 'red')\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def showPlot():\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5ca0e-99ce-4a7a-a222-6e2277b280af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [x for x in range(-10, 11, 1)]\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91d22a-57cf-463f-b6e6-9a35e655f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The answer to everything\n",
    "rnd.seed(42)\n",
    "\n",
    "a = 2\n",
    "b = 3\n",
    "c = -10\n",
    "\n",
    "# Prepare random data\n",
    "y = [a * x**2 + b * x + c for x in x]\n",
    "\n",
    "# Mean\n",
    "mu = 5\n",
    "\n",
    "# Define standard deviation (spread)\n",
    "sigma = 20\n",
    "\n",
    "# Prepare random data\n",
    "yNoise = [a * x**2 + b * x + c + rnd.gauss(mu, sigma) for x in x]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4647d61c-33c8-4edc-b356-f57dc689aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparePlot(\"Parabool\")\n",
    "plotCurve(x,y, False)\n",
    "plotCurve(x,yNoise, True)\n",
    "showPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421b00c-3903-426c-803e-e8c4e34b48d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Doel: best fit maken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100e5ee-acbe-4f07-9ba1-307a8d64f379",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ReLU: Rectified Linear Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf2502-27de-4664-866c-42ac0b2e4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "def relu(w, b, x):\n",
    "    \n",
    "    y = w * x + b\n",
    "    \n",
    "    if y > 0:\n",
    "        \n",
    "        \n",
    "        return y\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return 0\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dbeb1e-71f8-405a-8d80-6c3b65abee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "def manualRelu(w, b):\n",
    "    \n",
    "    rlu = [relu(w, b, x) for x in x]\n",
    "    \n",
    "    preparePlot(\"ReLU\")\n",
    "    \n",
    "    plotCurve(x, rlu, False)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "interact(manualRelu, w=(-30,30,0.1), b=(-100,100,0.1))\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875413a-ee27-4ef3-b317-f3bf1df27441",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Handmatige parabool fit met ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ed231-5941-48ad-8e64-67a9a22ab1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "def mse(fit):\n",
    "    \n",
    "    sse = 0\n",
    "    \n",
    "    # Sum of squared errors\n",
    "    for i in range(0, len(yNoise)):\n",
    "        \n",
    "        # Error = actual - predicted\n",
    "        err = yNoise[i] - fit[i]\n",
    "        sse += (err**2)\n",
    "    \n",
    "    # Mean squared error\n",
    "    return sse / len(yNoise)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def parabolaFit(w1, b1, w2, b2):\n",
    "    \n",
    "    fit = [relu(w1, b1, x) + relu(w2, b2, x) for x in x]\n",
    "    \n",
    "    preparePlot(\"Som van 2 ReLUs\")\n",
    "    \n",
    "    plotCurve(x, fit, False)\n",
    "    plotCurve(x, yNoise, True)\n",
    "    \n",
    "    showPlot()\n",
    "    \n",
    "    # Our indicator\n",
    "    print(mse(fit))\n",
    "\n",
    "#------------------------------------------\n",
    "    \n",
    "interact(parabolaFit, w1=(-50,50,0.01), b1=(-100,100,0.01), w2=(-50,50,0.01), b2=(-100,100,0.01))\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e292586-9762-4918-a02a-2c8bf1112451",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf91953-511e-43a6-b997-7a3a6464d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------\n",
    "\n",
    "# Learning iterations\n",
    "epochs = 100000\n",
    "\n",
    "# Learning rate\n",
    "learningRate = 1e-5\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "# Initial values (\"guess\")\n",
    "w1Fit = 0.0\n",
    "b1Fit = 0.0\n",
    "w2Fit = 0.0\n",
    "b2Fit = 0.0\n",
    "\n",
    "# Epochs counter\n",
    "epoch = 0\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def cost(w1, b1, w2, b2):\n",
    "    \n",
    "    sse = 0\n",
    "    \n",
    "    # Sum of squared errors\n",
    "    for i in range(0, len(yNoise)):\n",
    "        \n",
    "        # Use yhat = ReLU(w1 * x + b1) + ReLU(w2 * x + b2) + \n",
    "        yhat = relu(w1, b1, x[i]) + relu(w2, b2, x[i])\n",
    "        \n",
    "        # Use error = y - yhat\n",
    "        err = yNoise[i] - yhat\n",
    "        \n",
    "        sse += (err**2)\n",
    "    \n",
    "    # Mean squared error\n",
    "    return sse / len(yNoise)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def gradientDescent(w1, b1, w2, b2):\n",
    "    \n",
    "    # The change of our weights and biases\n",
    "    dw1 = 0\n",
    "    db1 = 0\n",
    "    \n",
    "    dw2 = 0\n",
    "    db2 = 0\n",
    "    \n",
    "    # Stochastic gradient descent\n",
    "    for i in range(0, len(yNoise)):\n",
    "    \n",
    "        # Use yhat = ReLU(w1 * x + b1) + ReLU(w2 * x + b2)\n",
    "        yhat = relu(w1, b1, x[i]) + relu(w2, b2, x[i])\n",
    "        \n",
    "        # Use error = y - yhat\n",
    "        err = yNoise[i] - yhat\n",
    "\n",
    "        # Gradient descent steps\n",
    "        dw1 -= 2 * err * x[i]\n",
    "        db1 -= 2 * err\n",
    "        \n",
    "        # Adjust with learn rate\n",
    "        w1 -= learningRate * dw1\n",
    "        b1 -= learningRate * db1\n",
    "        \n",
    "        # Use yhat = ReLU(w1 * x + b1) + ReLU(w2 * x + b2)\n",
    "        yhat = relu(w1, b1, x[i]) + relu(w2, b2, x[i])\n",
    "        \n",
    "        # Use error = y - yhat\n",
    "        err = yNoise[i] - yhat\n",
    "        \n",
    "        dw2 -= 2 * err * x[i]\n",
    "        db2 -= 2 * err\n",
    "        \n",
    "        # Adjust with learn rate\n",
    "        w2 -= learningRate * dw2\n",
    "        b2 -= learningRate * db2\n",
    "    \n",
    "    return w1, b1, w2, b2\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "def plotFit(w1, b1, w2, b2):\n",
    "    \n",
    "    fit = [relu(w1, b1, x) + relu(w2, b2, x) for x in x]\n",
    "    \n",
    "    preparePlot(\"Som van 2 ReLUs\")\n",
    "    \n",
    "    plotCurve(x, fit, False)\n",
    "    plotCurve(x, yNoise, True)\n",
    "    \n",
    "    showPlot()\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "# Inital cost\n",
    "mse = cost(w1Fit, b1Fit, w2Fit, b2Fit)\n",
    "\n",
    "print(\"initial cost: \", cost(w1Fit, b1Fit, w2Fit, b2Fit))\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "while epoch < epochs:\n",
    "    \n",
    "    # print(\"epoch: \", epoch)\n",
    "    \n",
    "    w1Fit, b1Fit, w2Fit, b2Fit = gradientDescent(w1Fit, b1Fit, w2Fit, b2Fit)\n",
    "    \n",
    "    # print(\"cost: \", cost(w1Fit, b1Fit, w2Fit, b2Fit))\n",
    "    \n",
    "    epoch += 1\n",
    "    \n",
    "#------------------------------------------\n",
    "\n",
    "print(\"w1Fit: \", w1Fit, \"b1Fit: \", b1Fit, \"w2Fit: \", w2Fit, \"b2Fit: \", b2Fit)\n",
    "print(\"final cost: \", cost(w1Fit, b1Fit, w2Fit, b2Fit))\n",
    "\n",
    "plotFit(w1Fit, b1Fit, w2Fit, b2Fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
